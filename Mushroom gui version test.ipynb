{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai.vision import *\n",
    "#from picamera import PiCamera\n",
    "from time import sleep\n",
    "from io import BytesIO\n",
    "import sounddevice as sd\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "import tkinter as tk\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import cv2 \n",
    "from time import sleep, strftime\n",
    "#import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "camera initialized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'fastai.layers.AdaptiveConcatPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveMaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'fastai.layers.Flatten' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/filip/anaconda3/envs/fastai57/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded...\n"
     ]
    }
   ],
   "source": [
    "print(\"Started\")\n",
    "\n",
    "\n",
    "\n",
    "#path = Path(\"/home/filip/Mushrooms\")  ##for rpi\n",
    "\n",
    "path = Path('/media/SSD/Mushrooms')  ##for desktop\n",
    "path_train = path / 'train'\n",
    "\n",
    "#camera=PiCamera()  ##for rpi\n",
    "#camera.resolution = (1024,768)  ##for rpi\n",
    "\n",
    "\n",
    "\n",
    "print(\"camera initialized...\")\n",
    "learn = load_learner(path_train,\"squeezenet11_export.pkl\");\n",
    "learn.to_fp32();\n",
    "print(\"model loaded...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 0.5\n",
    "frequency = 1000\n",
    "duration = 0.1\n",
    "modulationf=1\n",
    "start_idx = 0\n",
    "\n",
    "def sinewave(t,amplitude = 0.5,frequency = 0,phase = 0):\n",
    "    return amplitude*np.sin(phase+2 * np.pi * frequency * t)\n",
    "\n",
    "def gate(t,duration):\n",
    "    return (t<duration)\n",
    "\n",
    "def periodicgate(t,frequency,delay = 0.25, stop=0.50):\n",
    "    x=((t* frequency) % 1)/frequency\n",
    "    return (x>=delay) & (x<=stop)\n",
    "\n",
    "def sawtoothwave(t,frequency,delay=0):\n",
    "    return (delay+  frequency * t) % 1 \n",
    "\n",
    "samplerate = 16000\n",
    "\n",
    "def callback(outdata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    global start_idx\n",
    "    t = (start_idx + np.arange(frames)) / samplerate\n",
    "    t = t.reshape(-1, 1)\n",
    "    outdata[:] = sinewave(t,frequency=frequency) * periodicgate(t,modulationf,0,.05)\n",
    "    start_idx += frames\n",
    "    # use repeating function to repeat pulse (div or mod?).  Also can ramp up and down using modulating sine a lower freq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timer_running = True\n",
    "\n",
    "#stream=BytesIO()  ##for rpi\n",
    "\n",
    "#camera.capture(stream,format='jpeg',resize=(224,224))  ##for rpi\n",
    "#stream.seek(0)  ##for rpi\n",
    "#image=PIL.Image.open(stream).convert('RGB')  ##for rpi\n",
    "\n",
    "camera = cv2.VideoCapture(0) ##for desktop\n",
    "ret = camera.set(3,224)\n",
    "ret = camera.set(4,224)\n",
    "\n",
    "s, image = camera.read() ##for desktop\n",
    "image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  ##for desktop\n",
    "#plt.imshow(image)\n",
    "#imgtk = PIL.ImageTk.PhotoImage(image)\n",
    "\n",
    "while True:\n",
    "    with sd.OutputStream( channels=1, callback=callback,\n",
    "                         samplerate=samplerate):\n",
    "        if timer_running:\n",
    "\n",
    "\n",
    "            ## rpi\n",
    "            #stream=BytesIO()\n",
    "            #camera.capture(stream,format='jpeg',resize=(224,224))\n",
    "            #stream.seek(0)\n",
    "            #image=PIL.Image.open(stream).convert('RGB')\n",
    "\n",
    "            ##for desktop\n",
    "            s, image = camera.read() ##for desktop\n",
    "            image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  ##for desktop\n",
    "            img=Image(pil2tensor(image,np.float32).div_(255))\n",
    "            #print(\"image captured and saved...\")\n",
    "\n",
    "            #image=np.empty((240,320,3),dtype=np.uint8)\n",
    "            #camera.capture(image, 'rgb')\n",
    "            #img=Image(tensor(image))\n",
    "            pred_class,pred_idx,outputs = learn.predict(img)\n",
    "            sleep(.1)\n",
    "            prob=outputs[0].tolist()\n",
    "            print(pred_class,prob)\n",
    "            \n",
    "            modulationf=prob*100\n",
    "        \n",
    "        \n",
    "camera.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "layout = [  [sg.Text('Stopwatch', size=(20, 2), justification='center')],\n",
    "            [sg.Text('', size=(10, 2), font=('Helvetica', 20), justification='center', key='_OUTPUT_')],\n",
    "            [sg.T(' ' * 5), sg.Button('Start/Stop', focus=True), sg.Quit()]]\n",
    "\n",
    "window = sg.Window('Stopwatch Timer', layout)\n",
    "event, values = window.Read() \n",
    "window.Close()\n",
    "print(event, values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "layout = [  [sg.Text('Stopwatch', size=(20, 2), justification='center')],\n",
    "            [sg.Text('', size=(10, 2), font=('Helvetica', 20), justification='center', key='_OUTPUT_')],\n",
    "            [sg.T(' ' * 5), sg.Button('Start/Stop', focus=True), sg.Quit()]]\n",
    "\n",
    "window = sg.Window('Stopwatch Timer', layout)\n",
    "\n",
    "timer_running, i = True, 0\n",
    "\n",
    "while True:        # Event Loop\n",
    "    event, values = window.Read(timeout=10) # Please try and use as high of a timeout value as you can\n",
    "    if event is None or event == 'Quit':    # if user closed the window using X or clicked Quit button\n",
    "        break\n",
    "    elif event == 'Start/Stop':\n",
    "        timer_running = not timer_running\n",
    "    if timer_running:\n",
    "        window.Element('_OUTPUT_').Update('{:02d}:{:02d}.{:02d}'.format((i // 100) // 60, (i // 100) % 60, i % 100))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses a ram io file to store image to get to PySimpleGUI\n",
    "\n",
    "def take_picture():\n",
    "    ##for desktop\n",
    "    camera = cv2.VideoCapture(0) ##for desktop\n",
    "    ret = camera.set(3,224)\n",
    "    ret = camera.set(4,224)\n",
    "    s, image = camera.read() ##for desktop\n",
    "    camera.release()            \n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  ##for desktop\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    \n",
    "    #stream=BytesIO()  ##for rpi\n",
    "    #camera.capture(stream,format='jpeg',resize=(224,224))  ##for rpi\n",
    "    #stream.seek(0)  ##for rpi\n",
    "    #image=PIL.Image.open(stream).convert('RGB')  ##for rpi\n",
    "\n",
    "    return image\n",
    "\n",
    "image = take_picture()\n",
    "\n",
    "b = io.BytesIO()                   # open a binary, memory-resident file-like\n",
    "#image.save(b, \"ppm\")                 # save the image to it using a tkinter compatible format\n",
    "image.save(b, \"png\")\n",
    "imdata = b.getvalue() \n",
    "\n",
    "\n",
    "layout = [  [sg.Text('Mushroom Type', size=(20, 1), font=('Helvetica', 12), justification='center')],\n",
    "        [sg.Image(data = imdata, key='_IMAGE_')],\n",
    "        [sg.Text('', size=(20, 1), font=('Helvetica', 12), justification='center', key='_CLASS_')],\n",
    "        [sg.Text('', size=(20, 1), font=('Helvetica', 12), justification='center', key='_PROB_')],\n",
    "        [sg.Button('Correction', focus=True), sg.Quit()]]\n",
    "\n",
    "window = sg.Window('Mushroom AI', layout)\n",
    "\n",
    "event, values = window.Read(timeout=1)\n",
    "\n",
    "amplitude = .5\n",
    "frequency = 1000\n",
    "duration = 0.1\n",
    "modulationf=1\n",
    "start_idx = 0\n",
    "\n",
    "def sinewave(t,amplitude = 0.5,frequency = 0,phase = 0):\n",
    "    return amplitude*np.sin(phase+2 * np.pi * frequency * t)\n",
    "\n",
    "def gate(t,duration):\n",
    "    return (t<duration)\n",
    "\n",
    "def periodicgate(t,frequency,delay = 0.25, stop=0.50):\n",
    "    x=((t* frequency) % 1)/frequency\n",
    "    return (x>=delay) & (x<=stop)\n",
    "\n",
    "def sawtoothwave(t,frequency,delay=0):\n",
    "    return (delay+  frequency * t) % 1 \n",
    "\n",
    "#define pulse(x,duration):\n",
    "    \n",
    "#try:\n",
    "samplerate = 16000\n",
    "\n",
    "def callback(outdata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    global start_idx\n",
    "    t = (start_idx + np.arange(frames)) / samplerate\n",
    "    t = t.reshape(-1, 1)\n",
    "    outdata[:] = sinewave(t,frequency=frequency) * periodicgate(t,modulationf,0,.05)\n",
    "    start_idx += frames\n",
    "    # use repeating function to repeat pulse (div or mod?).  Also can ramp up and down using modulating sine a lower freq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timer_running = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#s, image = camera.read() ##for desktop\n",
    "#image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  ##for desktop\n",
    "#plt.imshow(image)\n",
    "#imgtk = PIL.ImageTk.PhotoImage(image)\n",
    "\n",
    "while True:\n",
    "    with sd.OutputStream( channels=1, callback=callback,\n",
    "                         samplerate=samplerate):\n",
    "        #print('#' * 80)\n",
    "        #print('press Return to quit')\n",
    "        #print('#' * 80)\n",
    "        #frequency = frequency +100\n",
    "        #sleep(.1)\n",
    "\n",
    "        event, values = window.Read(timeout=1) # Please try and use as high of a timeout value as you can\n",
    "        if event is None or event == 'Quit':    # if user closed the window using X or clicked Quit button\n",
    "            break\n",
    "        #elif event == 'Correction':\n",
    "        #    timer_running = not timer_running\n",
    "        if timer_running:\n",
    "\n",
    "\n",
    "\n",
    "            image = take_picture()\n",
    "            img=Image(pil2tensor(image,np.float32).div_(255))\n",
    "            \n",
    "            pred_class,pred_idx,outputs = learn.predict(img)\n",
    "            sleep(.5)\n",
    "            prob=outputs[0].tolist()\n",
    "            #print(pred_class,prob)\n",
    "            \n",
    "            modulationf=prob*100\n",
    "            b = io.BytesIO()                   # open a binary, memory-resident file-like\n",
    "            image.save(b, \"png\")                 # save the image to it using a tkinter compatible format\n",
    "            imdata = b.getvalue() \n",
    "\n",
    "            \n",
    "            window.Element('_IMAGE_').Update(data=imdata )\n",
    "            window.Element('_PROB_').Update(f'prob: {(prob*100.0):02.2f} %')\n",
    "            window.Element('_CLASS_').Update(str(pred_class))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses a ram io file to store image to get to PySimpleGUI\n",
    "## saves incorrect images\n",
    "\n",
    "def take_picture():\n",
    "    ##for desktop\n",
    "    camera = cv2.VideoCapture(0) ##for desktop\n",
    "    ret = camera.set(3,224)\n",
    "    ret = camera.set(4,224)\n",
    "    s, image = camera.read() ##for desktop\n",
    "    camera.release()            \n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  ##for desktop\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    \n",
    "    #stream=BytesIO()  ##for rpi\n",
    "    #camera.capture(stream,format='jpeg',resize=(224,224))  ##for rpi\n",
    "    #stream.seek(0)  ##for rpi\n",
    "    #image=PIL.Image.open(stream).convert('RGB')  ##for rpi\n",
    "\n",
    "    return image\n",
    "\n",
    "image = take_picture()\n",
    "\n",
    "b = BytesIO()                   # open a binary, memory-resident file-like\n",
    "image.save(b, \"png\")\n",
    "imdata = b.getvalue() \n",
    "\n",
    "\n",
    "layout = [  [sg.Text('Mushroom Type', size=(20, 1), font=('Helvetica', 12), justification='center')],\n",
    "        [sg.Image(data = imdata, key='_IMAGE_')],\n",
    "        [sg.Text('', size=(20, 1), font=('Helvetica', 12), justification='center', key='_CLASS_')],\n",
    "        [sg.Text('', size=(20, 1), font=('Helvetica', 12), justification='center', key='_PROB_')],\n",
    "        [sg.Button('Correction', focus=True), sg.Quit()]]\n",
    "\n",
    "window = sg.Window('Mushroom AI', layout,no_titlebar=True, location=(0,0), keep_on_top=True).Finalize()\n",
    "\n",
    "\n",
    "window.Maximize()\n",
    "\n",
    "event, values = window.Read(timeout=1)\n",
    "\n",
    "amplitude = .5\n",
    "frequency = 1000\n",
    "duration = 0.1\n",
    "modulationf=1\n",
    "start_idx = 0\n",
    "\n",
    "def sinewave(t,amplitude = 0.5,frequency = 0,phase = 0):\n",
    "    return amplitude*np.sin(phase+2 * np.pi * frequency * t)\n",
    "\n",
    "def gate(t,duration):\n",
    "    return (t<duration)\n",
    "\n",
    "def periodicgate(t,frequency,delay = 0.25, stop=0.50):\n",
    "    x=((t* frequency) % 1)/frequency\n",
    "    return (x>=delay) & (x<=stop)\n",
    "\n",
    "def sawtoothwave(t,frequency,delay=0):\n",
    "    return (delay+  frequency * t) % 1 \n",
    "\n",
    "#define pulse(x,duration):\n",
    "    \n",
    "#try:\n",
    "samplerate = 16000\n",
    "\n",
    "def callback(outdata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    global start_idx\n",
    "    t = (start_idx + np.arange(frames)) / samplerate\n",
    "    t = t.reshape(-1, 1)\n",
    "    outdata[:] = sinewave(t,frequency=frequency) * periodicgate(t,modulationf,0,.05)\n",
    "    start_idx += frames\n",
    "    # use repeating function to repeat pulse (div or mod?).  Also can ramp up and down using modulating sine a lower freq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#s, image = camera.read() ##for desktop\n",
    "#image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  ##for desktop\n",
    "#plt.imshow(image)\n",
    "#imgtk = PIL.ImageTk.PhotoImage(image)\n",
    "\n",
    "while True:\n",
    "    with sd.OutputStream( channels=1, callback=callback,\n",
    "                         samplerate=samplerate):\n",
    "        #print('#' * 80)\n",
    "        #print('press Return to quit')\n",
    "        #print('#' * 80)\n",
    "        #frequency = frequency +100\n",
    "        #sleep(.1)\n",
    "\n",
    "        event, values = window.Read(timeout=10) # Please try and use as high of a timeout value as you can\n",
    "        if event is None or event == 'Quit':    # if user closed the window using X or clicked Quit button\n",
    "            window.Close()\n",
    "            break\n",
    "            \n",
    "            \n",
    "        if event == 'Correction' and str(pred_class) == 'chanterelles':\n",
    "            image.save(str(path/'corrections/other/not_chant') + strftime('%Y-%m-%d-%X')+str('.jpg'),'JPEG')\n",
    "            \n",
    "        if event == 'Correction' and str(pred_class) == 'other':\n",
    "            image.save(str(path/'corrections/chanterelles/chant') + strftime('%Y-%m-%d-%X')+str('.jpg'),'JPEG')\n",
    "        \n",
    "\n",
    "        image = take_picture()\n",
    "        img=Image(pil2tensor(image,np.float32).div_(255))\n",
    "\n",
    "        pred_class,pred_idx,outputs = learn.predict(img)\n",
    "        sleep(.5)\n",
    "        prob=outputs[0].tolist()\n",
    "        #print(pred_class,prob)\n",
    "\n",
    "        modulationf=prob*100\n",
    "        b = BytesIO()                   # open a binary, memory-resident file-like\n",
    "        image.save(b, \"png\")                 # save the image to it using a tkinter compatible format\n",
    "        imdata = b.getvalue() \n",
    "\n",
    "\n",
    "        window.Element('_IMAGE_').Update(data=imdata )\n",
    "        window.Element('_PROB_').Update(f'prob: {(prob*100.0):02.2f} %')\n",
    "        window.Element('_CLASS_').Update(str(pred_class))\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strftime('%Y-%m-%d-%X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
